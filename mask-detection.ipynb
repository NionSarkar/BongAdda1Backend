{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1187790,"sourceType":"datasetVersion","datasetId":675484},{"sourceId":1386555,"sourceType":"datasetVersion","datasetId":809358},{"sourceId":7304856,"sourceType":"datasetVersion","datasetId":4238277}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ironman45/mask-detection?scriptVersionId=162817934\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-11T21:24:41.155281Z","iopub.execute_input":"2024-02-11T21:24:41.155694Z","iopub.status.idle":"2024-02-11T21:24:55.810823Z","shell.execute_reply.started":"2024-02-11T21:24:41.155665Z","shell.execute_reply":"2024-02-11T21:24:55.809809Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.listdir('/kaggle/input')","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:24:55.812504Z","iopub.execute_input":"2024-02-11T21:24:55.812797Z","iopub.status.idle":"2024-02-11T21:24:55.819289Z","shell.execute_reply.started":"2024-02-11T21:24:55.812768Z","shell.execute_reply":"2024-02-11T21:24:55.818457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout,BatchNormalization \nfrom tensorflow.keras.models import Sequential \nimport matplotlib.pyplot as plt\n\ndata=tf.keras.utils.image_dataset_from_directory(\"/kaggle/input/face-mask-dataset/data\",batch_size=32) \ndata=data.map(lambda x,y:(x/255.0,y))\n\ndata_i=data.as_numpy_iterator()","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:24:55.820418Z","iopub.execute_input":"2024-02-11T21:24:55.820673Z","iopub.status.idle":"2024-02-11T21:24:58.151478Z","shell.execute_reply.started":"2024-02-11T21:24:55.82065Z","shell.execute_reply":"2024-02-11T21:24:58.150547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing the Dataset for training and validation","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\nbatch_size=32\n\nTrain_Datagen = ImageDataGenerator(dtype = 'float32', preprocessing_function=tf.keras.applications.resnet.preprocess_input)\nVal_Datagen = ImageDataGenerator(dtype = 'float32', preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n\ntrain_gen = Train_Datagen.flow_from_directory(directory = '/kaggle/input/face-mask-12k-images-dataset/Face Mask Dataset/Train', target_size = (256,256), \n                                       batch_size = batch_size, class_mode = 'binary')\n\nval_gen = Val_Datagen.flow_from_directory(directory = '/kaggle/input/face-mask-12k-images-dataset/Face Mask Dataset/Validation', target_size = (256,256), \n                                       batch_size = batch_size, class_mode = 'binary')","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:24:58.153801Z","iopub.execute_input":"2024-02-11T21:24:58.154093Z","iopub.status.idle":"2024-02-11T21:24:58.510651Z","shell.execute_reply.started":"2024-02-11T21:24:58.154068Z","shell.execute_reply":"2024-02-11T21:24:58.509711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building The CNN model for Mask Detection","metadata":{}},{"cell_type":"code","source":"model=Sequential()\n\npretrained_model=tf.keras.applications.ResNet50(\n    include_top=False,\n    weights='imagenet',\n    \n    input_shape=(256,256,3),\n    pooling='avg',\n)\n\nfor layer in pretrained_model.layers:\n    layer.trainable=False\n\nmodel.add(pretrained_model)\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile('adam',loss=tf.losses.BinaryCrossentropy(),metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:24:58.51198Z","iopub.execute_input":"2024-02-11T21:24:58.512564Z","iopub.status.idle":"2024-02-11T21:25:00.773289Z","shell.execute_reply.started":"2024-02-11T21:24:58.512525Z","shell.execute_reply":"2024-02-11T21:25:00.772517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:25:00.77441Z","iopub.execute_input":"2024-02-11T21:25:00.774753Z","iopub.status.idle":"2024-02-11T21:25:00.814207Z","shell.execute_reply.started":"2024-02-11T21:25:00.774715Z","shell.execute_reply":"2024-02-11T21:25:00.813394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"hist=model.fit(train_gen,epochs=15,validation_data=val_gen)","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:25:00.815518Z","iopub.execute_input":"2024-02-11T21:25:00.815873Z","iopub.status.idle":"2024-02-11T21:36:33.060038Z","shell.execute_reply.started":"2024-02-11T21:25:00.815839Z","shell.execute_reply":"2024-02-11T21:36:33.05923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot of Training Loss vs Validation Loss","metadata":{}},{"cell_type":"code","source":"plt.plot(hist.history['loss'],color='red',label='loss');\nplt.plot(hist.history['val_loss'],color='green',label='val_loss');\n","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:36:33.061454Z","iopub.execute_input":"2024-02-11T21:36:33.061803Z","iopub.status.idle":"2024-02-11T21:36:33.331643Z","shell.execute_reply.started":"2024-02-11T21:36:33.06177Z","shell.execute_reply":"2024-02-11T21:36:33.330659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot of Training Accuracy vs Validation Accuracy","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:21:15.714172Z","iopub.execute_input":"2024-02-11T21:21:15.715004Z","iopub.status.idle":"2024-02-11T21:21:15.721045Z","shell.execute_reply.started":"2024-02-11T21:21:15.714968Z","shell.execute_reply":"2024-02-11T21:21:15.719812Z"}}},{"cell_type":"code","source":"plt.plot(hist.history['accuracy'],color='red',label='loss');\nplt.plot(hist.history['val_accuracy'],color='green',label='val_loss');\n","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:36:33.332772Z","iopub.execute_input":"2024-02-11T21:36:33.333058Z","iopub.status.idle":"2024-02-11T21:36:33.590984Z","shell.execute_reply.started":"2024-02-11T21:36:33.333033Z","shell.execute_reply":"2024-02-11T21:36:33.590106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\npre=Precision()\nre=Recall()\nacc=BinaryAccuracy()","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:36:33.593605Z","iopub.execute_input":"2024-02-11T21:36:33.593903Z","iopub.status.idle":"2024-02-11T21:36:33.607713Z","shell.execute_reply.started":"2024-02-11T21:36:33.593876Z","shell.execute_reply":"2024-02-11T21:36:33.606665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating Test Data","metadata":{}},{"cell_type":"code","source":"Test_Datagen = ImageDataGenerator(dtype = 'float32', preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n\ntest_gen = Test_Datagen.flow_from_directory(directory = '/kaggle/input/face-mask-12k-images-dataset/Face Mask Dataset/Test', target_size = (256,256), \n                                       batch_size = 32, class_mode = 'binary')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:36:33.608691Z","iopub.execute_input":"2024-02-11T21:36:33.609006Z","iopub.status.idle":"2024-02-11T21:36:33.647989Z","shell.execute_reply.started":"2024-02-11T21:36:33.608981Z","shell.execute_reply":"2024-02-11T21:36:33.647277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(30):\n    batch=test_gen[i]\n    x,y=batch\n    ypred=model.predict(x)\n    pre.update_state(y,ypred)\n    re.update_state(y,ypred)\n    acc.update_state(y,ypred)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:36:33.649132Z","iopub.execute_input":"2024-02-11T21:36:33.649862Z","iopub.status.idle":"2024-02-11T21:36:44.477532Z","shell.execute_reply.started":"2024-02-11T21:36:33.649819Z","shell.execute_reply":"2024-02-11T21:36:44.476762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Accuracy","metadata":{}},{"cell_type":"code","source":"print(pre.result().numpy())\nprint(re.result().numpy())\nprint(acc.result().numpy())","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:36:44.478601Z","iopub.execute_input":"2024-02-11T21:36:44.478862Z","iopub.status.idle":"2024-02-11T21:36:44.488271Z","shell.execute_reply.started":"2024-02-11T21:36:44.478839Z","shell.execute_reply":"2024-02-11T21:36:44.487242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nfrom keras.applications.vgg16 import preprocess_input\nimage=data.as_numpy_iterator().next()\nX,y=image\n\nfig = plt.figure(figsize=(32,32)) \n\n\nfor i in range(32):\n    fig.add_subplot(8, 4, i+1) \n\n    plt.imshow((X[i]*255).astype(int))\n\n    my_image = img_to_array(X[i]*255)\n    my_image = my_image.reshape((1, my_image.shape[0], my_image.shape[1], my_image.shape[2]))\n    my_image = preprocess_input(my_image)\n\n\n\n    pre=model.predict(my_image)\n    if(pre<0.5):\n        plt.title(\"MASK ON\",color='green') \n    else:\n        plt.title(\"NO MASK\",color='red') \n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-11T21:36:44.489522Z","iopub.execute_input":"2024-02-11T21:36:44.490196Z","iopub.status.idle":"2024-02-11T21:36:57.097341Z","shell.execute_reply.started":"2024-02-11T21:36:44.49016Z","shell.execute_reply":"2024-02-11T21:36:57.095857Z"},"trusted":true},"execution_count":null,"outputs":[]}]}